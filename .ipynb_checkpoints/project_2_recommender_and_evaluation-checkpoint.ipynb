{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alike-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-knitting",
   "metadata": {},
   "source": [
    "# Load the dataset for recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "victorian-bottom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>term</th>\n",
       "      <th>length_of_stay_bucket</th>\n",
       "      <th>rate_plan</th>\n",
       "      <th>room_segment</th>\n",
       "      <th>n_people_bucket</th>\n",
       "      <th>weekend_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Easter</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = os.path.join(\"data\", \"hotel_data\")\n",
    "\n",
    "interactions_df = pd.read_csv(os.path.join(data_path, \"hotel_data_interactions_df.csv\"), index_col=0)\n",
    "\n",
    "base_item_features = ['term', 'length_of_stay_bucket', 'rate_plan', 'room_segment', 'n_people_bucket', 'weekend_stay']\n",
    "\n",
    "column_values_dict = {\n",
    "    'term': ['WinterVacation', 'Easter', 'OffSeason', 'HighSeason', 'LowSeason', 'MayLongWeekend', 'NewYear', 'Christmas'],\n",
    "    'length_of_stay_bucket': ['[0-1]', '[2-3]', '[4-7]', '[8-inf]'],\n",
    "    'rate_plan': ['Standard', 'Nonref'],\n",
    "    'room_segment': ['[0-160]', '[160-260]', '[260-360]', '[360-500]', '[500-900]'],\n",
    "    'n_people_bucket': ['[1-1]', '[2-2]', '[3-4]', '[5-inf]'],\n",
    "    'weekend_stay': ['True', 'False']\n",
    "}\n",
    "\n",
    "interactions_df.loc[:, 'term'] = pd.Categorical(\n",
    "    interactions_df['term'], categories=column_values_dict['term'])\n",
    "interactions_df.loc[:, 'length_of_stay_bucket'] = pd.Categorical(\n",
    "    interactions_df['length_of_stay_bucket'], categories=column_values_dict['length_of_stay_bucket'])\n",
    "interactions_df.loc[:, 'rate_plan'] = pd.Categorical(\n",
    "    interactions_df['rate_plan'], categories=column_values_dict['rate_plan'])\n",
    "interactions_df.loc[:, 'room_segment'] = pd.Categorical(\n",
    "    interactions_df['room_segment'], categories=column_values_dict['room_segment'])\n",
    "interactions_df.loc[:, 'n_people_bucket'] = pd.Categorical(\n",
    "    interactions_df['n_people_bucket'], categories=column_values_dict['n_people_bucket'])\n",
    "interactions_df.loc[:, 'weekend_stay'] = interactions_df['weekend_stay'].astype('str')\n",
    "interactions_df.loc[:, 'weekend_stay'] = pd.Categorical(\n",
    "    interactions_df['weekend_stay'], categories=column_values_dict['weekend_stay'])\n",
    "\n",
    "# display(interactions_df[interactions_df.isna().any(axis=1)])\n",
    "\n",
    "# drop rows with NaN value\n",
    "interactions_df.dropna(inplace=True)\n",
    "display(HTML(interactions_df.head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-third",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical user features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based user features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "variable-jaguar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_term_WinterVacation', 'user_term_Easter', 'user_term_OffSeason', 'user_term_HighSeason', 'user_term_LowSeason', 'user_term_MayLongWeekend', 'user_term_NewYear', 'user_term_Christmas', 'user_length_of_stay_bucket_[0-1]', 'user_length_of_stay_bucket_[2-3]', 'user_length_of_stay_bucket_[4-7]', 'user_length_of_stay_bucket_[8-inf]', 'user_rate_plan_Standard', 'user_rate_plan_Nonref', 'user_room_segment_[0-160]', 'user_room_segment_[160-260]', 'user_room_segment_[260-360]', 'user_room_segment_[360-500]', 'user_room_segment_[500-900]', 'user_n_people_bucket_[1-1]', 'user_n_people_bucket_[2-2]', 'user_n_people_bucket_[3-4]', 'user_n_people_bucket_[5-inf]', 'user_weekend_stay_True', 'user_weekend_stay_False']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_term_WinterVacation</th>\n",
       "      <th>user_term_Easter</th>\n",
       "      <th>user_term_OffSeason</th>\n",
       "      <th>user_term_HighSeason</th>\n",
       "      <th>user_term_LowSeason</th>\n",
       "      <th>user_term_MayLongWeekend</th>\n",
       "      <th>user_term_NewYear</th>\n",
       "      <th>user_term_Christmas</th>\n",
       "      <th>user_length_of_stay_bucket_[0-1]</th>\n",
       "      <th>user_length_of_stay_bucket_[2-3]</th>\n",
       "      <th>user_length_of_stay_bucket_[4-7]</th>\n",
       "      <th>user_length_of_stay_bucket_[8-inf]</th>\n",
       "      <th>user_rate_plan_Standard</th>\n",
       "      <th>user_rate_plan_Nonref</th>\n",
       "      <th>user_room_segment_[0-160]</th>\n",
       "      <th>user_room_segment_[160-260]</th>\n",
       "      <th>user_room_segment_[260-360]</th>\n",
       "      <th>user_room_segment_[360-500]</th>\n",
       "      <th>user_room_segment_[500-900]</th>\n",
       "      <th>user_n_people_bucket_[1-1]</th>\n",
       "      <th>user_n_people_bucket_[2-2]</th>\n",
       "      <th>user_n_people_bucket_[3-4]</th>\n",
       "      <th>user_n_people_bucket_[5-inf]</th>\n",
       "      <th>user_weekend_stay_True</th>\n",
       "      <th>user_weekend_stay_False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>50</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>96</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>706</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>1736</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7283</th>\n",
       "      <td>7779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def n_to_p(l):\n",
    "    n = sum(l)\n",
    "    return [x / n for x in l] if n > 0 else l\n",
    "\n",
    "def calculate_p(x, values):\n",
    "    counts = [0]*len(values)\n",
    "    for v in x:\n",
    "        counts[values.index(v)] += 1\n",
    "\n",
    "    return n_to_p(counts)\n",
    "\n",
    "\n",
    "def prepare_users_df(interactions_df):\n",
    "\n",
    "    users_df = interactions_df.loc[:, [\"user_id\"]]\n",
    "    users_df = users_df.groupby(\"user_id\").first().reset_index(drop=False)\n",
    "    \n",
    "    user_features = []\n",
    "\n",
    "    for column in base_item_features:\n",
    "\n",
    "        column_values = column_values_dict[column]\n",
    "        df = interactions_df.loc[:, ['user_id', column]]\n",
    "        df = df.groupby('user_id').aggregate(lambda x: list(x)).reset_index(drop=False)\n",
    "\n",
    "        df.loc[:, column] = df[column].apply(lambda x: calculate_p(x, column_values))\n",
    "\n",
    "        p_columns = []\n",
    "        for i in range(len(column_values)):\n",
    "            p_columns.append(\"user_\" + column + \"_\" + column_values[i])\n",
    "            df.loc[:, p_columns[i]] = df[column].apply(lambda x: x[i])\n",
    "            user_features.append(p_columns[i])\n",
    "\n",
    "        users_df = pd.merge(users_df, df.loc[:, ['user_id'] + p_columns], on=[\"user_id\"])\n",
    "    \n",
    "    return users_df, user_features\n",
    "    \n",
    "\n",
    "users_df, user_features = prepare_users_df(interactions_df)\n",
    "\n",
    "print(user_features)\n",
    "\n",
    "display(HTML(users_df.loc[users_df['user_id'].isin([706, 1736, 7779, 96, 1, 50, 115])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-keyboard",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical item features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based item features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "formal-munich",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['term_WinterVacation', 'term_Easter', 'term_OffSeason', 'term_HighSeason', 'term_LowSeason', 'term_MayLongWeekend', 'term_NewYear', 'term_Christmas', 'length_of_stay_bucket_[0-1]', 'length_of_stay_bucket_[2-3]', 'length_of_stay_bucket_[4-7]', 'length_of_stay_bucket_[8-inf]', 'rate_plan_Standard', 'rate_plan_Nonref', 'room_segment_[0-160]', 'room_segment_[160-260]', 'room_segment_[260-360]', 'room_segment_[360-500]', 'room_segment_[500-900]', 'n_people_bucket_[1-1]', 'n_people_bucket_[2-2]', 'n_people_bucket_[3-4]', 'n_people_bucket_[5-inf]', 'weekend_stay_True', 'weekend_stay_False']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>term_WinterVacation</th>\n",
       "      <th>term_Easter</th>\n",
       "      <th>term_OffSeason</th>\n",
       "      <th>term_HighSeason</th>\n",
       "      <th>term_LowSeason</th>\n",
       "      <th>term_MayLongWeekend</th>\n",
       "      <th>term_NewYear</th>\n",
       "      <th>term_Christmas</th>\n",
       "      <th>length_of_stay_bucket_[0-1]</th>\n",
       "      <th>length_of_stay_bucket_[2-3]</th>\n",
       "      <th>length_of_stay_bucket_[4-7]</th>\n",
       "      <th>length_of_stay_bucket_[8-inf]</th>\n",
       "      <th>rate_plan_Standard</th>\n",
       "      <th>rate_plan_Nonref</th>\n",
       "      <th>room_segment_[0-160]</th>\n",
       "      <th>room_segment_[160-260]</th>\n",
       "      <th>room_segment_[260-360]</th>\n",
       "      <th>room_segment_[360-500]</th>\n",
       "      <th>room_segment_[500-900]</th>\n",
       "      <th>n_people_bucket_[1-1]</th>\n",
       "      <th>n_people_bucket_[2-2]</th>\n",
       "      <th>n_people_bucket_[3-4]</th>\n",
       "      <th>n_people_bucket_[5-inf]</th>\n",
       "      <th>weekend_stay_True</th>\n",
       "      <th>weekend_stay_False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_items_to_onehot(df):\n",
    "    one_hot = pd.get_dummies(df.loc[:, base_item_features])\n",
    "    df = df.drop(base_item_features, axis = 1)\n",
    "    df = df.join(one_hot)\n",
    "    \n",
    "    return df, list(one_hot.columns)\n",
    "\n",
    "def prepare_items_df(interactions_df):\n",
    "    items_df = interactions_df.loc[:, [\"item_id\"] + base_item_features].drop_duplicates()\n",
    "    \n",
    "    items_df, item_features = map_items_to_onehot(items_df)\n",
    "    \n",
    "    return items_df, item_features\n",
    "\n",
    "\n",
    "items_df, item_features = prepare_items_df(interactions_df)\n",
    "\n",
    "print(item_features)\n",
    "\n",
    "display(HTML(items_df.loc[items_df['item_id'].isin([0, 1, 2, 3, 4, 5, 6])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enclosed-receptor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Ti Laptop GPU'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PLAYGROUND ###\n",
    "display(len(users_df.columns))\n",
    "display(len(user_features))\n",
    "\n",
    "#torch.cuda.is_available()\n",
    "#torch.cuda.device_count()\n",
    "#torch.cuda.current_device()\n",
    "#torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-imaging",
   "metadata": {},
   "source": [
    "# Neural network recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Code a recommender based on a neural network model. You are free to choose any network architecture you find appropriate. The network can use the interaction vectors for users and items, embeddings of users and items, as well as user and item features (you can use the features you developed in the first project).\n",
    "\n",
    "Remember to keep control over randomness - in the init method add the seed as a parameter and initialize the random seed generator with that seed (both for numpy and pytorch):\n",
    "\n",
    "```python\n",
    "self.seed = seed\n",
    "self.rng = np.random.RandomState(seed=seed)\n",
    "```\n",
    "in the network model:\n",
    "```python\n",
    "self.seed = torch.manual_seed(seed)\n",
    "```\n",
    "\n",
    "You are encouraged to experiment with:\n",
    "  - the number of layers in the network, the number of neurons and different activation functions,\n",
    "  - different optimizers and their parameters,\n",
    "  - batch size and the number of epochs,\n",
    "  - embedding layers,\n",
    "  - content-based features of both users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "organic-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_negative_interactions(interactions_df, rng, negative_interactions_size):\n",
    "    negative_interactions = []\n",
    "    \n",
    "    max_user = interactions_df['user_id'].max()\n",
    "    max_item = interactions_df['item_id'].max()\n",
    "\n",
    "    # print(max_user, max_item)\n",
    "    \n",
    "    positive_interactions = interactions_df[['user_id', 'item_id']].to_numpy()\n",
    "    \n",
    "    while (len(negative_interactions) < negative_interactions_size):\n",
    "        user_id = rng.choice(max_user + 1)\n",
    "        item_id = rng.choice(max_item + 1)\n",
    "        \n",
    "        negative_interaction = tuple((user_id, item_id))\n",
    "        \n",
    "        if not (negative_interaction == positive_interactions).all(axis=1).any():\n",
    "            negative_interactions.append(tuple((user_id, item_id, 0)))\n",
    "\n",
    "            \n",
    "    return negative_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unlike-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.recommender import Recommender\n",
    "from collections import deque\n",
    "\n",
    "class NNRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Linear recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self, seed=6789, n_neg_per_pos=7, device='cuda:0', \n",
    "            lr=0.001, weight_decay=0.0001, n_epochs=5, embedding_dim=16,\n",
    "            batch_size=16\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Initialize recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.item_id_mapping = None\n",
    "        self.user_id_mapping = None\n",
    "        self.item_id_reverse_mapping = None\n",
    "        self.user_id_reverse_mapping = None\n",
    "        self.r = None\n",
    "        \n",
    "        self.model = None\n",
    "        self.device = torch.device(device)\n",
    "        self.optimizer = None\n",
    "        \n",
    "        self.recommender_df = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        self.users_df = None\n",
    "        self.user_features = None\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "        self.validation_set_size = 0.2\n",
    "        \n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_neg_per_pos = n_neg_per_pos\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = (int(embedding_dim / 2) if embedding_dim is not None else 4)\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        interactions_df = interactions_df.copy()\n",
    "        \n",
    "        del users_df, items_df\n",
    "\n",
    "        # Shift item ids and user ids so that they are consecutive\n",
    "        unique_item_ids = interactions_df['item_id'].unique()\n",
    "        self.item_id_mapping = dict(zip(unique_item_ids, list(range(len(unique_item_ids)))))\n",
    "        self.item_id_reverse_mapping = dict(zip(list(range(len(unique_item_ids))), unique_item_ids))\n",
    "        unique_user_ids = interactions_df['user_id'].unique()\n",
    "        self.user_id_mapping = dict(zip(unique_user_ids, list(range(len(unique_user_ids)))))\n",
    "        self.user_id_reverse_mapping = dict(zip(list(range(len(unique_user_ids))), unique_user_ids))\n",
    "\n",
    "        interactions_df['item_id'] = interactions_df['item_id'].map(self.item_id_mapping)\n",
    "        interactions_df['user_id'] = interactions_df['user_id'].map(self.user_id_mapping)\n",
    "        \n",
    "        # Get the number of items and users\n",
    "        n_users = np.max(interactions_df['user_id']) + 1\n",
    "        n_items = np.max(interactions_df['item_id']) + 1\n",
    "        \n",
    "        # Get the user-item interaction matrix (mapping to int is necessary because of how iterrows works)\n",
    "        # r = np.zeros(shape=(n_users, n_items))\n",
    "        # for idx, interaction in interactions_df.iterrows():\n",
    "        #    r[int(interaction['user_id'])][int(interaction['item_id'])] = 1\n",
    "\n",
    "        # self.r = r\n",
    "        \n",
    "        # Indicate positive interactions\n",
    "        \n",
    "        interactions_df.loc[:, 'interacted'] = 1\n",
    "        \n",
    "        # Prepare users_df and items_df \n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        # users_df, user_features = prepare_users_df(interactions_df)\n",
    "        \n",
    "        # self.users_df = users_df\n",
    "        # self.user_features = user_features\n",
    "        \n",
    "        # items_df, item_features = prepare_items_df(interactions_df)\n",
    "        # items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "        \n",
    "        # Generate negative interactions\n",
    "        neg_inter_size = int(len(interactions_df) * self.n_neg_per_pos)\n",
    "        negative_interactions = rand_negative_interactions(interactions_df, self.rng, neg_inter_size)\n",
    "                \n",
    "        interactions_df = pd.concat(\n",
    "            [interactions_df, pd.DataFrame(negative_interactions, columns=['user_id', 'item_id', 'interacted'])])\n",
    "        interactions_df = interactions_df.reset_index(drop=True)\n",
    "        \n",
    "        # Merge user and item features\n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        #interactions_df = pd.merge(interactions_df, users_df, on=['user_id'])\n",
    "        #interactions_df = pd.merge(interactions_df, items_df, on=['item_id'])\n",
    "        \n",
    "        # Initialize the neural network model\n",
    "        # num_columns = len(user_features)\n",
    "        # n_items = len(items_df.index)\n",
    "        # n_users = len(users_df.index)\n",
    "        # display(n_items, n_users)\n",
    "        \n",
    "        self.model = MLPModel(n_items, n_users, self.embedding_dim, self.hidden_dim, self.seed)\n",
    "        self.model.train()\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        \n",
    "        liveloss = PlotLosses()\n",
    "        \n",
    "        training_losses = deque(maxlen=50)\n",
    "        training_avg_losses = []\n",
    "        training_epoch_losses = []\n",
    "        last_training_total_loss = 0.0\n",
    "        \n",
    "        validation_losses = deque(maxlen=50)\n",
    "        validation_avg_losses = []\n",
    "        validation_epoch_losses = []\n",
    "        last_validation_total_loss = 0.0\n",
    "        \n",
    "        interaction_ids = self.rng.permutation(len(interactions_df))\n",
    "        train_validation_slice_idx = int(len(interactions_df) * (1 - self.validation_set_size))\n",
    "        training_ids = interaction_ids[:train_validation_slice_idx]\n",
    "        validation_ids = interaction_ids[train_validation_slice_idx:]\n",
    "        \n",
    "        # Train the model using an optimizer\n",
    "        for epoch in range(self.n_epochs):\n",
    "            logs = {}\n",
    "            \n",
    "            training_losses.clear()\n",
    "            training_total_loss = 0.0\n",
    "            \n",
    "            self.rng.shuffle(training_ids)\n",
    "            \n",
    "            batch_idx = 0\n",
    "            n_batches = int(np.ceil(len(training_ids) / self.batch_size))\n",
    "            \n",
    "            for batch_idx in range(n_batches):\n",
    "                \n",
    "                batch_ids = training_ids[(batch_idx * self.batch_size):((batch_idx + 1) * self.batch_size)]\n",
    "                # display(batch_ids)\n",
    "                batch = interactions_df.loc[batch_ids]\n",
    "                batch_input = torch.from_numpy(batch.loc[:, ['user_id', 'item_id']].values).long().to(self.device)\n",
    "                y_target = torch.from_numpy(batch.loc[:, ['interacted']].values).float().to(self.device)\n",
    "                \n",
    "                # Create responses\n",
    "                y = self.model(batch_input).clip(0.000001, 0.999999)\n",
    "\n",
    "                # Define loss and backpropagate\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = -(y_target * y.log() + (1 - y_target) * (1 - y).log()).sum()\n",
    "                \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                training_total_loss += loss.item()\n",
    "                \n",
    "                print(\"\\rEpoch: {}\\tBatch: {}\\tLast epoch - avg training loss: {:.2f} avg validation loss: {:.2f} loss: {}\".format(\n",
    "                        epoch, batch_idx, last_training_total_loss, last_validation_total_loss, loss), end=\"\")\n",
    "                \n",
    "                training_losses.append(loss.item())\n",
    "                training_avg_losses.append(np.mean(training_losses))\n",
    "                \n",
    "                \n",
    "                \n",
    "            # Save and print epoch losses\n",
    "            training_last_avg_loss = training_total_loss / len(training_ids)\n",
    "            \n",
    "            # Validate\n",
    "            validation_total_loss = 0.0\n",
    "\n",
    "            batch = interactions_df.loc[validation_ids]\n",
    "            batch_input = torch.from_numpy(batch.loc[:, ['user_id', 'item_id']].values).long().to(self.device)\n",
    "            y_target = torch.from_numpy(batch.loc[:, ['interacted']].values).float().to(self.device)\n",
    "\n",
    "            # Create responses\n",
    "            y = self.model(batch_input).clip(0.000001, 0.999999)\n",
    "\n",
    "            # Calculate validation loss\n",
    "            loss = -(y_target * y.log() + (1 - y_target) * (1 - y).log()).sum()\n",
    "            validation_total_loss += loss.item()\n",
    "            \n",
    "            validation_last_avg_loss = validation_total_loss / len(validation_ids)\n",
    "            \n",
    "            if epoch >= 0:\n",
    "                logs['loss'] = training_last_avg_loss\n",
    "                logs['val_loss'] = validation_last_avg_loss\n",
    "                liveloss.update(logs)\n",
    "                liveloss.send()                                                                   \n",
    "            \n",
    "            \n",
    "        # Find the most popular items for the cold start problem\n",
    "        offers_count = interactions_df.loc[:, ['item_id', 'user_id']].groupby(by='item_id').count()\n",
    "        offers_count = offers_count.sort_values('user_id', ascending=False)\n",
    "        self.most_popular_items = offers_count.index\n",
    "            \n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Clean previous recommendations (iloc could be used alternatively)\n",
    "        self.recommender_df = self.recommender_df[:0]\n",
    "        \n",
    "        # Prepare users_df and items_df\n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        users_df = users_df.loc[:, 'user_id']\n",
    "        users_df = pd.merge(users_df, self.users_df, on=['user_id'], how='left').fillna(0)\n",
    "        \n",
    "        items_df, item_features = prepare_items_df(items_df)\n",
    "        items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "        \n",
    "        # Score the items\n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            \n",
    "            # Calculate the score for the user and every item in items_df\n",
    "            # <<<Write your code here>>>\n",
    "            \n",
    "            scores = []\n",
    "\n",
    "            chosen_ids = np.argsort(-scores)[:n_recommendations]\n",
    "            \n",
    "            recommendations = []\n",
    "            for item_id in chosen_ids:\n",
    "                recommendations.append(\n",
    "                    {\n",
    "                        'user_id': user['user_id'],\n",
    "                        'item_id': item_id,\n",
    "                        'score': scores[item_id]\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            user_recommendations = pd.DataFrame(recommendations)\n",
    "\n",
    "            self.recommender_df = pd.concat([self.recommender_df, user_recommendations])\n",
    "\n",
    "        return self.recommender_df\n",
    "    \n",
    "### Two Layer Model ###\n",
    "class TwoLayerModel(nn.Module):\n",
    "    def __init__(self, in_neurons, hidden_neurons, seed):\n",
    "        \"\"\"\n",
    "        :param int in_neurons: Number of in neurons.\n",
    "        :param int hidden_neurons: Number of neurons in first hidden layer.\n",
    "        :param int seed: Seed for the random number generator.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "\n",
    "        hidden_neurons_2 = int(hidden_neurons / 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_neurons, hidden_neurons, bias=False)\n",
    "        self.fc2 = nn.Linear(hidden_neurons, hidden_neurons_2, bias=False)\n",
    "        self.fc3 = nn.Linear(hidden_neurons_2, 1, bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "### GMF Model ###\n",
    "class GMFModel(nn.Module):\n",
    "    def __init__(self, n_items, n_users, embedding_dim, seed):\n",
    "        \"\"\"\n",
    "        :param int n_items: Number of items.\n",
    "        :param int n_users: Number of users.\n",
    "        :param int embedding_dim: Dimension of the user and item embeddings.\n",
    "        :param int seed: Seed for the random number generator.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        \n",
    "        # display(\"n_items: \", n_items)\n",
    "        # display(\"n_users: \", n_users)\n",
    "        \n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, 1, bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param torch.Tensor x: Tensor of size batch_size x 2. Every row contains two values - user id in the first column \n",
    "            and item id in the second column.\n",
    "        \"\"\"\n",
    "        user_ids = x[:, 0]\n",
    "        item_ids = x[:, 1]\n",
    "        # display(\"user_ids: \", len(user_ids))\n",
    "        # display(\"item_ids: \", len(item_ids))\n",
    "        user_embedding = self.user_embedding(user_ids)\n",
    "        item_embedding = self.item_embedding(item_ids)\n",
    "        x = self.fc(user_embedding * item_embedding)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "### MLP Model ###\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, n_items, n_users, embedding_dim, hidden_dim, seed):\n",
    "        \"\"\"\n",
    "        :param int n_items: Number of items.\n",
    "        :param int n_users: Number of users.\n",
    "        :param int embedding_dim: Dimension of the user and item embeddings.\n",
    "        :param int hidden_dim: Dimension of the first hidden layer.\n",
    "        :param int seed: Seed for the random number generator.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_dim_lay_2 = int(hidden_dim / 2)\n",
    "        \n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, hidden_dim, bias=True)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim_lay_2, bias=True)\n",
    "        self.fc3 = nn.Linear(hidden_dim_lay_2, 1, bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param torch.Tensor x: Tensor of size batch_size x 2. Every row contains two values - user id in the first column \n",
    "            and item id in the second column.\n",
    "        \"\"\"\n",
    "        user_ids = x[:, 0]\n",
    "        item_ids = x[:, 1]\n",
    "        x = torch.cat([self.user_embedding(user_ids), self.item_embedding(item_ids)], dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-relative",
   "metadata": {},
   "source": [
    "# Quick test of the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "greatest-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = interactions_df.loc[:, ['item_id'] + base_item_features].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-capital",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    0.241, max:    0.274, cur:    0.241)\n",
      "\tvalidation       \t (min:    0.275, max:    0.293, cur:    0.293)\n",
      "Epoch: 4\tBatch: 1407\tLast epoch - avg training loss: 0.00 avg validation loss: 0.00 loss: 5.36502742767334154"
     ]
    }
   ],
   "source": [
    "# Fit method\n",
    "nn_recommender = NNRecommender()\n",
    "nn_recommender.fit(interactions_df, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-consolidation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recommender method\n",
    "\n",
    "recommendations = nn_recommender.recommend(pd.DataFrame([[1], [2], [3], [4], [5]], columns=['user_id']), items_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, items_df, on='item_id', how='left')\n",
    "display(HTML(recommendations.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-eleven",
   "metadata": {},
   "source": [
    "# Tuning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_and_testing.testing import evaluate_train_test_split_implicit\n",
    "\n",
    "seed = 6789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "import traceback\n",
    "\n",
    "def tune_recommender(recommender_class, interactions_df, items_df, \n",
    "                     param_space, max_evals=1, show_progressbar=True, seed=6789):\n",
    "    # Split into train_validation and test sets\n",
    "\n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    split_index = int(len(interactions_df) * train_test_split)\n",
    "\n",
    "    train_validation = interactions_df.iloc[shuffle[:split_index]]\n",
    "    test = interactions_df.iloc[shuffle[split_index:]]\n",
    "\n",
    "    # Tune\n",
    "\n",
    "    def loss(tuned_params):\n",
    "        recommender = recommender_class(seed=seed, **tuned_params)\n",
    "        hr1, hr3, hr5, hr10, ndcg1, ndcg3, ndcg5, ndcg10 = evaluate_train_test_split_implicit(\n",
    "            recommender, train_validation, items_df, seed=seed)\n",
    "        return -hr10\n",
    "\n",
    "    n_tries = 1\n",
    "    succeded = False\n",
    "    try_id = 0\n",
    "    while not succeded and try_id < n_tries:\n",
    "        try:\n",
    "            trials = Trials()\n",
    "            best_param_set = fmin(loss, space=param_space, algo=tpe.suggest, \n",
    "                                  max_evals=max_evals, show_progressbar=show_progressbar, trials=trials, verbose=True)\n",
    "            succeded = True\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            try_id += 1\n",
    "            \n",
    "    if not succeded:\n",
    "        return None\n",
    "        \n",
    "    # Validate\n",
    "    \n",
    "    recommender = recommender_class(seed=seed, **best_param_set)\n",
    "\n",
    "    results = [[recommender_class.__name__] + list(evaluate_train_test_split_implicit(\n",
    "        recommender, {'train': train_validation, 'test': test}, items_df, seed=seed))]\n",
    "\n",
    "    results = pd.DataFrame(results, \n",
    "                           columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "    display(HTML(results.to_html()))\n",
    "    \n",
    "    return best_param_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-switzerland",
   "metadata": {},
   "source": [
    "## Tuning of the recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Tune your model using the code below. You only need to put the class name of your recommender and choose an appropriate parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'n_neg_per_pos': hp.quniform('n_neg_per_pos', 1, 10, 1)\n",
    "}\n",
    "\n",
    "best_param_set = tune_recommender(NNRecommender, interactions_df, items_df,\n",
    "                                  param_space, max_evals=10, show_progressbar=True, seed=seed)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_param_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-strap",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Run the final evaluation of your recommender and present its results against the Amazon and Netflix recommenders' results. You just need to give the class name of your recommender and its tuned parameters below.\n",
    "\n",
    "It's optional, but for better effect you can include here the results from all recommenders created during in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_recommender = NNRecommender(n_neg_per_pos=1)  # Initialize your recommender here\n",
    "\n",
    "# Give the name of your recommender in the line below\n",
    "nn_tts_results = [['NNRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    nn_recommender, interactions_df, items_df))]\n",
    "\n",
    "nn_tts_results = pd.DataFrame(\n",
    "    nn_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(nn_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.amazon_recommender import AmazonRecommender\n",
    "\n",
    "amazon_recommender = AmazonRecommender()\n",
    "\n",
    "amazon_tts_results = [['AmazonRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    amazon_recommender, interactions_df, items_df))]\n",
    "\n",
    "amazon_tts_results = pd.DataFrame(\n",
    "    amazon_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(amazon_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.netflix_recommender import NetflixRecommender\n",
    "\n",
    "netflix_recommender = NetflixRecommender(embedding_dim=8, n_epochs=200, print_type='live')\n",
    "\n",
    "netflix_tts_results = [['NetflixRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    netflix_recommender, interactions_df, items_df))]\n",
    "\n",
    "netflix_tts_results = pd.DataFrame(\n",
    "    netflix_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(netflix_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_results = pd.concat([nn_tts_results, amazon_tts_results, netflix_tts_results]).reset_index(drop=True)\n",
    "display(HTML(tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-vegetable",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Write a summary of your experiments. What worked well and what did not? What are your thoughts how could you possibly further improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neg_per_pos=5, embedding_dim=4, batch_size=64 -> terrible results, after 30 epochs loss for validation\n",
    "data set > 1.4, loss for training data set > 0.6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
